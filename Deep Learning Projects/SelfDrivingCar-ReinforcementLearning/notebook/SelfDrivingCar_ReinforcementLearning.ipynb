{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import gymnasium as gym\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback\n",
        "from stable_baselines3.common.vec_env import VecVideoRecorder\n"
      ],
      "metadata": {
        "id": "SLVot-hC6RGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set configurations\n",
        "CONFIG = {\n",
        "    \"env_name\": \"CarRacing-v3\",\n",
        "    \"timesteps\": 500_000,\n",
        "    \"checkpoint_dir\": \"./checkpoints/\",\n",
        "    \"video_dir\": \"./videos/\",\n",
        "    \"save_model_path\": \"./ppo_carracing_model.zip\",\n",
        "    \"evaluate_episodes\": 5,\n",
        "    \"video_length\": 1000,\n",
        "    \"seed\": 42,\n",
        "}\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "q8yKm5KIqOj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and preprocess the environment\n",
        "def create_env(env_name, monitor_path=None):\n",
        "    env = gym.make(env_name, render_mode=\"rgb_array\")\n",
        "    env.reset(seed=CONFIG[\"seed\"])\n",
        "    if monitor_path:\n",
        "        env = Monitor(env, monitor_path)\n",
        "    return DummyVecEnv([lambda: env])\n",
        ""
      ],
      "metadata": {
        "id": "MmURP_yjqZqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "def setup_directories():\n",
        "    os.makedirs(CONFIG[\"checkpoint_dir\"], exist_ok=True)\n",
        "    os.makedirs(CONFIG[\"video_dir\"], exist_ok=True)\n",
        "\n",
        "def create_model(env):\n",
        "    return PPO(\n",
        "        \"CnnPolicy\",\n",
        "        env,\n",
        "        verbose=1,\n",
        "        tensorboard_log=\"./tensorboard_logs/\",\n",
        "        seed=CONFIG[\"seed\"],\n",
        "        device=DEVICE\n",
        "    )\n",
        "\n",
        "def train_model(model, env):\n",
        "    checkpoint_callback = CheckpointCallback(\n",
        "        save_freq=10_000,\n",
        "        save_path=CONFIG[\"checkpoint_dir\"],\n",
        "        name_prefix=\"ppo_carracing_checkpoint\"\n",
        "    )\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    model.learn(\n",
        "        total_timesteps=CONFIG[\"timesteps\"],\n",
        "        callback=checkpoint_callback\n",
        "    )\n",
        "    print(\"Training complete.\")\n",
        "\n",
        "    model.save(CONFIG[\"save_model_path\"])\n",
        ""
      ],
      "metadata": {
        "id": "6-xV6azJqpwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "def evaluate_model(model, env, episodes):\n",
        "    total_rewards = []\n",
        "    for episode in range(episodes):\n",
        "        obs = env.reset()\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "        while not done:\n",
        "            action, _ = model.predict(obs, deterministic=True)\n",
        "            obs, reward, done, info = env.step(action)\n",
        "            total_reward += reward\n",
        "        total_rewards.append(total_reward)\n",
        "        print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
        "    avg_reward = np.mean(total_rewards)\n",
        "    print(f\"Average Reward over {episodes} episodes: {avg_reward}\")\n",
        "    return avg_reward\n",
        "\n",
        "def record_video(env, model, video_length, video_path):\n",
        "    env = VecVideoRecorder(\n",
        "        env,\n",
        "        video_path,\n",
        "        record_video_trigger=lambda x: x == 0,\n",
        "        video_length=video_length,\n",
        "        name_prefix=\"ppo_carracing\"\n",
        "    )\n",
        "    obs = env.reset()\n",
        "    for _ in range(video_length):\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "        obs, _, done, info = env.step(action)\n",
        "        if done:\n",
        "            obs = env.reset()\n",
        "    env.close()\n",
        ""
      ],
      "metadata": {
        "id": "7cnTdLvBqwQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Setup\n",
        "    setup_directories()\n",
        "    env = create_env(CONFIG[\"env_name\"])\n",
        "\n",
        "    # Training\n",
        "    model = create_model(env)\n",
        "    train_model(model, env)\n",
        "\n",
        "    # Evaluation\n",
        "    print(\"Final evaluation...\")\n",
        "    final_reward = evaluate_model(model, env, CONFIG[\"evaluate_episodes\"])\n",
        "    print(f\"Final evaluation completed. Average reward: {final_reward}\")\n",
        "\n",
        "main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BXXiC-3Lqsl",
        "outputId": "75276cba-13a5-416e-9c91-523256b3fd83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final evaluation...\n",
            "Episode 1: Total Reward = [69.61107]\n",
            "Episode 2: Total Reward = [425.24808]\n",
            "Episode 3: Total Reward = [313.83887]\n",
            "Episode 4: Total Reward = [289.23624]\n",
            "Episode 5: Total Reward = [167.26285]\n",
            "Average Reward over 5 episodes: 253.03939819335938\n",
            "Final evaluation completed. Average reward: 253.03939819335938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization\n",
        "def visualize_agent(model_path, video_path=\"agent_gameplay.mp4\", num_episodes=3, fps=60):\n",
        "    env = gym.make(\"CarRacing-v3\", render_mode=\"rgb_array\")\n",
        "    model = PPO.load(model_path)\n",
        "\n",
        "    desired_width = 800\n",
        "    desired_height = 600\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(video_path, fourcc, fps, (desired_width, desired_height))\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        obs, _ = env.reset()\n",
        "        done = truncated = False\n",
        "        total_reward = 0\n",
        "\n",
        "        while not (done or truncated):\n",
        "            action, _ = model.predict(obs, deterministic=True)\n",
        "            obs, reward, done, truncated, _ = env.step(action)\n",
        "            total_reward += reward\n",
        "\n",
        "            frame = cv2.cvtColor(obs, cv2.COLOR_RGB2BGR)\n",
        "            frame = cv2.resize(frame, (desired_width, desired_height),\n",
        "                             interpolation=cv2.INTER_LANCZOS4)\n",
        "\n",
        "            cv2.putText(frame, f\"Episode: {episode+1}\", (20, 40),\n",
        "                       cv2.FONT_HERSHEY_DUPLEX, 1, (255, 255, 255), 2)\n",
        "            cv2.putText(frame, f\"Reward: {total_reward:.1f}\", (20, 80),\n",
        "                       cv2.FONT_HERSHEY_DUPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "            out.write(frame)\n",
        "\n",
        "        print(f\"Episode {episode+1} completed with reward: {total_reward:.2f}\")\n",
        "\n",
        "    out.release()\n",
        "    env.close()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KCvuZgfl0S1",
        "outputId": "e4201378-5a7d-4c53-9829-ea5844f051b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1 completed with reward: 924.40\n",
            "Episode 2 completed with reward: 463.38\n",
            "Episode 3 completed with reward: 252.38\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}